---
title: "Predicting Exercising manner with classification methods"
author: "K S Raghuram"
date: "31 March 2017"
output: word_document
---

## Backgroud Check

Majority of the attention in human activity recognition research focuses on discrimination between different type of activities, but not quality of the activities. In this study, the goal is to investigate how well an activity was performed by six wearers of electronic devices. These six participants were between 20 to 28 years with little weight lifting experience. They were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions, namely

Class A: exactly according to the specification
Class B: throwing the elbows to the front
Class C: lifting the dumbbell only halfway
Class D: lowering the dumbbell only half way
Class E: throwing the hips to the front.

Notice that only class A corresponds to the specified execution of the exercise, and others correspond to common mistakes. To ensure the quality of data, an experienced weight lifter was there to supervise the participants



## Goal

The goal of this project is to predict the manner in which the participants did the exercise. In other words, we need to predict the different fashions of the Unilateral Dumbbell Biceps crul performed by the participants. It is the classe varaible in the dataset, and we can use any of the other variables to predict with.

## Getting Started

### Set the directory

First lets set up the directory. 

```{r}
setwd("C:/Users/raghu/Desktop/Coursera/ML")
```

### Installing and Loading the packages

These are the packages which will be needed for the codes to run with the appropriate accuracy. 

```{r}

library(caret)
library(ggplot2)
library(randomForest)
```

### Reading the train and test data 

```{r}
train <- read.csv("train.csv")
test <- read.csv("test.csv")
```

## Processing the data 

When we closely look at the data, we see many of the predictors have empty strings as their values and it doesnt make any sense converting them into "NA" values and then replacing them with the zero or mean of the columns. So, we directly delete them from the train data set. 

```{r}
train <- train[,-c(12,13,14,15,16,17,20,23,26,69,70,71,72,73,74,87,88,89,90,91,92,95,98,101,125,126,127,128,129,130,133,136,139)]
```

Now we have to replace the "NA" values with either the zero or the mean or the median of their respective columns and after many experiments, I have concluded that we should impute the values with zero. 

```{r}
train[is.na(train)] <- 0
```

There are many predictors which dont explain any variance, i.e. the values of the columns are factors of only 1 level, so that means that the variance would be nearly zero. There is a function in the {caret} package which explains the work we want to do. This is called removing the nearly zero variance showing predictors from the data.

```{r}
nzv <- nearZeroVar(train, saveMetrics = FALSE)
train <- train[,-nzv]
```

### Centering and scaling 

As the metrics of the data columns are not known to us, we shoud always normalize the data for proper results. In the "preProcess" function, we have the centering and scaling option which divides normalizes each data point. 

```{r}
mod <- preProcess(training, method = c("center", "scale"))


training <- predict(mod, training)
testing <- predict(mod, testing)

```

### Data Partitioning 

As we are all set with the preprocessing of the data we had, we go with the data partitioning where we divide our data into 60% training data and 40% testing data using {createDataPartition} from the caret package. 

```{r}
intrain <- createDataPartition(train$classe, p = 0.6, list = FALSE)

training <- train[intrain,]
testing <- train[-intrain,]
```

## Feature Selection 

As we are left with the 58 predictor variables and 1 response variable, lets narrow down the number of predictors to less than 15-20. SO, there is a recursive feature elimination method which uses backward process of selection of features using Random forest algorithm for k = 2 in the cross validation. It keeps on adding one predictor and for each set, calculates the  accuracy and thereby selects the best accurate result. 

```{r}
control <- rfeControl(functions=rfFuncs, method="cv", number=2)

results <- rfe(training[,1:57], training[,58], sizes=c(1:57), rfeControl=control)

print(results)

predictors(results)
```

### Final Features 

As we see from the results that there are 4 important features which are having the major impact on the accuracy achieved in this rfe random forest algorithm. We will use these features to predict the final results and thereby finding the rmse value or the accuracy value. 
We have used the random forest algorithm because from various experiments, we know that random forest has the highest accuracy as compared to the normal decision trees or the linear models. 

So, random forest is applied to these 4 important predictors. 

```{r}
ranfo <- randomForest( classe~raw_timestamp_part_1 + cvtd_timestamp + roll_belt+num_window ,
                      data = training, do.trace = 100)
print(fit_rf, digits = 4)
```

Then we predict and thereby find the accuracy with the intrain testing model. 

```{r, echo=FALSE}
pred <- predict(ranfo, testing, type = "class")

confusionMatrix(pred, testing$classe)
```

## Out of sample error 

The algorithm's accuracy turned out to be 0.9985. so, the out of sample error would be 1- 0.9985 = 0.002. 

## Prediction 

Prediction is also made for the 20 samples given out as the actual test data. We will first read the data and then predict the ranfo model onto it. 
```{r}
testData <- read.csv("test.csv")
```

```{r}
predict(ranfo, testData)

```

